{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import matplotlib.image as mpimg\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.patches as patches\n",
    "#from matplotlib.patches import Rectangle\n",
    "#from PIL import Image\n",
    "#%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download SVHN and extract from label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "\n",
    "svhn_images = imp.load_source('svhn_images', '../modules/svhn_images.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_path='/flat2/raw'\n",
    "if not os.path.exists(image_path): \n",
    "    os.mkdir(image_path)\n",
    "\n",
    "for data_kind in [ 'test']:\n",
    "#for data_kind in ['train', 'test']:\n",
    "    print \"Processing %s, please give this a few minutes to complete\" % data_kind\n",
    "\n",
    "    svhn_images.download_and_extract_SVHN(data_kind, image_path, '../data/SVHN/%s' % data_kind)\n",
    "\n",
    "    print \"Finished processing %s\" % data_kind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_path='/flat2/raw'\n",
    "\n",
    "image_counts = svhn_images.count_images_by_length(image_path, data_kind='train')\n",
    "\n",
    "print \"Train data set:\"\n",
    "for k,v in image_counts.items():\n",
    "    print \"Number of %d-digit sequences=%d\" %(k, v)\n",
    "    \n",
    "image_counts = svhn_images.count_images_by_length(image_path, data_kind='test')\n",
    "\n",
    "print \"Test data set:\"\n",
    "for k,v in image_counts.items():\n",
    "    print \"Number of %d-digit sequences=%d\" %(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_of_images = svhn_images.get_list_of_filenames(image_path, data_kind='train', batch_size=10, max_sequence_length=3)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "for f in [ \"%s/images/%s/%s\" % (image_path, 'train', png) for png in sample_of_images]:\n",
    "    \n",
    "    plt.figure()\n",
    "    img = mpimg.imread(f)\n",
    "    \n",
    "    print img.shape\n",
    "    plt.imshow(img, cmap='Greys', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore sample after image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y1, y2, y3 = svhn_images.load_batch(sample_of_images, image_path, 'train', 10, 64, 3)\n",
    "\n",
    "for i,_ in enumerate(sample_of_images):\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.imshow(X[i].reshape(64,64,3), cmap='Greys', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = imp.load_source('model', '../modules/model.py')\n",
    "\n",
    "m = model.Model()\n",
    "tf_graph = m.getGraph()\n",
    "session = m.init_interactive_session(tf_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.load_saved_model('/flat2/saved_models/SVHN_3_digit_May7', session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demostrate a few learning epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "keep_prob=0.5\n",
    "image_path='/flat2/raw'\n",
    "\n",
    "# Total test set with 3 digits or less is 31958\n",
    "NUMBER_OF_TRAIN_IMAGES = 31958\n",
    "train_images_filenames = svhn_images.get_list_of_filenames(image_path, data_kind='train', batch_size=NUMBER_OF_TRAIN_IMAGES, max_sequence_length=3)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "#running 10 epochs for demonstration only\n",
    "for i in range(10):\n",
    "    offset = random.randint(0, NUMBER_OF_TRAIN_IMAGES - batch_size)\n",
    "    x, y1, y2, y3 = svhn_images.load_batch(train_images_filenames[offset:(offset+batch_size)],\\\n",
    "                                       image_path, 'train', 10, 64, 3)           \n",
    "    m.run_training_epoch(session, x, y1, y2, y3, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model against the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total test set with 3 digits or less is 12920\n",
    "image_path='/flat2/raw'\n",
    "\n",
    "NUMBER_OF_TEST_IMAGES = 12920\n",
    "\n",
    "test_images_filenames = svhn_images.get_list_of_filenames(image_path, data_kind='test', batch_size=NUMBER_OF_TEST_IMAGES, max_sequence_length=3)\n",
    "\n",
    "# Test the images against the model in a small batch at a time, to avoid memory exhaustion errors\n",
    "\n",
    "batch_size = NUMBER_OF_TEST_IMAGES / 20\n",
    "i=0\n",
    "digit1 = []\n",
    "digit2 = []\n",
    "digit3 = []\n",
    "\n",
    "while i < (NUMBER_OF_TEST_IMAGES - batch_size):\n",
    "    batch_images = test_images_filenames[i:i+batch_size]\n",
    "    X, y1, y2, y3 = svhn_images.load_batch(batch_images, image_path, 'test', 10, 64, 3)\n",
    "    \n",
    "    d1_acc, d2_acc, d3_acc = m.test_model(session, X, y1, y2, y3)\n",
    "    digit1.append(d1_acc)\n",
    "    digit2.append(d2_acc)\n",
    "    digit3.append(d3_acc)\n",
    "    i=i+batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: digit_1 = 0.752 digit_2 = 0.659 digit_3 = 0.895 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print \"Mean accuracy: digit_1 = %0.3f digit_2 = %0.3f digit_3 = %0.3f \" % (np.array(digit1).mean(), np.array(digit2).mean(), np.array(digit3).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
